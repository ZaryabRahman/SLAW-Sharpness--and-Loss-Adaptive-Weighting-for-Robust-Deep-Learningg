# -*- coding: utf-8 -*-
"""SLAW:Sharpness-and-Loss-Adaptive-Weighting-for-Robust-Deep-Learning-Personal-Lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lIbaw6S0RhyC_4DyYwJODCzAOR_Z3xeo

# **Expirement 01**

## SETUP AND IMPORTS
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
import pandas as pd
import pickle
import os

# For reproducibility
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# Check for GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Create directories for saving results
os.makedirs('results', exist_ok=True)
os.makedirs('plots', exist_ok=True)

"""## The SLAW"""

class SLAW:
    """ SLAW  - Uses retain_graph=True for the correct autograd handling. """
    def __init__(self, model, num_classes,
                 alpha=0.2, eps_min=0.0, eps_max=0.2, sharp_ema_decay=0.99,
                 tau=1.0, beta=1.0, gamma=0.7,
                 sharpness_scope='last_layer'):

        self.m = model
        self.K = num_classes
        self.alpha, self.eps_min, self.eps_max = alpha, eps_min, eps_max
        self.decay = sharp_ema_decay
        self.sharp_ema = 1.0
        self.tau, self.beta, self.gamma = tau, beta, gamma
        self.device = next(model.parameters()).device
        self.step_idx = 0

        self.sharpness_scope = sharpness_scope
        self._grad_params = self._get_params_for_sharpness()
        if not self._grad_params:
            print("Warning: SLAW could not find parameters. Defaulting to full model.")
            self.sharpness_scope = 'full'
            self._grad_params = [p for p in self.m.parameters() if p.requires_grad]

    def _get_params_for_sharpness(self):
        if self.sharpness_scope == 'last_layer':
            last_layer = None
            for module in reversed(list(self.m.modules())):
                if isinstance(module, (nn.Linear, nn.Conv2d)) and hasattr(module, 'weight') and module.weight.requires_grad:
                    last_layer = module
                    break
            if last_layer:
                print(f"SLAW: Using last layer ({type(last_layer).__name__}) for sharpness proxy.")
                return list(last_layer.parameters())
            else: return []
        else:
            print("SLAW: Using full model for sharpness proxy.")
            return [p for p in self.m.parameters() if p.requires_grad]

    @torch.no_grad()
    def _update_sharp_ema(self, s_batch_float):
        self.sharp_ema = self.decay * self.sharp_ema + (1 - self.decay) * s_batch_float

    @torch.no_grad()
    def _get_sals_targets(self, probs, y, s_batch_tensor):
        conf = probs.max(dim=1).values
        sharpness_scale = (s_batch_tensor / (self.sharp_ema + 1e-12)).clamp(min=0.1, max=10.0)
        eps_i = (self.alpha * sharpness_scale * (1.0 - conf)).clamp(self.eps_min, self.eps_max)

        B = y.size(0)
        off_target_fill = eps_i.unsqueeze(1) / (self.K - 1 + 1e-12)
        t = off_target_fill.expand(-1, self.K).clone()
        t.scatter_(1, y.unsqueeze(1), 1.0 - eps_i.unsqueeze(1))
        return t, eps_i

    def _get_sharpness_proxy(self, logits, y):
        with torch.enable_grad():
            ce_loss_for_grad = F.cross_entropy(logits, y, reduction='mean')

            grads = torch.autograd.grad(ce_loss_for_grad, self._grad_params, create_graph=False, retain_graph=True)
        s_batch = torch.sqrt(sum((g.detach()**2).sum() for g in grads) + 1e-12)
        return s_batch

    def __call__(self, logits, y):
        self.step_idx += 1


        s_batch_tensor = self._get_sharpness_proxy(logits, y)

        self._update_sharp_ema(s_batch_tensor.item())
        sals_targets, eps_i_stats = self._get_sals_targets(logits.softmax(dim=1).detach(), y, s_batch_tensor)

        log_probs = F.log_softmax(logits, dim=1)
        sals_per_sample = -(sals_targets * log_probs).sum(dim=1)

        with torch.no_grad():
            loss_vals = sals_per_sample.detach()
            mu, std = loss_vals.mean(), loss_vals.std() + 1e-8
            standardized_loss = (loss_vals - mu) / std
            weights = (torch.sigmoid(standardized_loss / self.tau).pow(self.beta) * self.gamma) + (1 - self.gamma)

        slaw_loss = (weights * sals_per_sample).mean()
        metrics = {'s_batch': s_batch_tensor.item(), 'sharp_ema': self.sharp_ema, 'eps_mean': eps_i_stats.mean().item(), 'weight_mean': weights.mean().item()}
        return slaw_loss, metrics

"""## Data loading and model definition"""

print("Preparing CIFAR-10 data...")
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)

def get_model():
    model = torchvision.models.resnet18(weights='IMAGENET1K_V1')
    model.fc = nn.Linear(model.fc.in_features, 10)
    return model.to(device)

"""## TRAINING & EVALUATION UTILITIES"""

class History:
    def __init__(self): self.history = {}
    def new_run(self, name): self.history[name] = {'epochs': [], 'steps': []}
    def add_epoch_log(self, name, log): self.history[name]['epochs'].append(log)
    def add_step_log(self, name, log): self.history[name]['steps'].append(log)
    def get_epoch_df(self, name): return pd.DataFrame(self.history[name]['epochs'])
    def get_step_df(self, name): return pd.DataFrame(self.history[name]['steps'])
    def save(self, fp):
        with open(fp, 'wb') as f: pickle.dump(self.history, f)
    def load(self, fp):
        with open(fp, 'rb') as f: self.history = pickle.load(f)

def train_one_epoch(model, dataloader, criterion, optimizer, run_name, history_tracker):
    model.train()
    total_loss, total_correct, total_samples = 0, 0, 0
    progress_bar = tqdm(dataloader, desc="Training", leave=False)
    for inputs, targets in progress_bar:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        slaw_metrics = {}
        if isinstance(criterion, SLAW):
            loss, slaw_metrics = criterion(outputs, targets)
        else:
            loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * inputs.size(0)
        _, predicted = outputs.max(1)
        total_correct += predicted.eq(targets).sum().item()
        total_samples += inputs.size(0)
        if slaw_metrics: history_tracker.add_step_log(run_name, slaw_metrics)
        progress_bar.set_postfix(loss=total_loss/total_samples, acc=100.*total_correct/total_samples)
    return total_loss / total_samples, 100. * total_correct / total_samples

def evaluate(model, dataloader):
    model.eval()
    total_loss, total_correct, total_samples = 0, 0, 0
    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = F.cross_entropy(outputs, targets)
            total_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            total_correct += predicted.eq(targets).sum().item()
            total_samples += inputs.size(0)
    return total_loss / total_samples, 100. * total_correct / total_samples

"""## Main Expirement"""

N_EPOCHS = 50
LEARNING_RATE = 1e-3
WEIGHT_DECAY = 5e-4
HISTORY_FILE = 'results/cifar10_resnet18_history_v3.pkl'

experiment_configs = {
    "Baseline (CE)": {},
    "SLAW (last_layer)": {
        'alpha': 0.2, 'eps_max': 0.2, 'tau': 1.0, 'beta': 1.0, 'gamma': 0.7,
        'sharpness_scope': 'last_layer'
    }
}

try:
    history = History()
    history.load(HISTORY_FILE)
    print(f"Loaded existing history from {HISTORY_FILE}")
except FileNotFoundError:
    history = History()
    print("No existing history found. Starting a new one.")

for run_name, config in experiment_configs.items():
    if run_name in history.history and history.get_epoch_df(run_name).shape[0] >= N_EPOCHS:
        print(f"--> Skipping '{run_name}' as it's already completed in the history file.")
        continue

    print(f"\n{'='*20} Starting Run: {run_name} {'='*20}")
    set_seed(42)
    model = get_model()
    history.new_run(run_name)

    criterion = SLAW(model, 10, **config) if "SLAW" in run_name else nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)

    best_val_acc = 0.0
    for epoch in range(N_EPOCHS):
        train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer, run_name, history)
        val_loss, val_acc = evaluate(model, testloader)
        scheduler.step()

        print(f"Epoch {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        history.add_epoch_log(run_name, {'epoch': epoch, 'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc})

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            model_path = f"results/{run_name}_best_model.pth"
            torch.save(model.state_dict(), model_path)
            print(f"  -> New best model saved to {model_path} (Acc: {best_val_acc:.2f}%)")

    print(f"Finished run {run_name}. Best Validation Accuracy: {best_val_acc:.2f}%")

    history.save(HISTORY_FILE)
    print(f"History updated and saved to '{HISTORY_FILE}'")

print("\nAll experiments complete.")

"""## plotting and analysis"""

print("\nGenerating plots from final history...")
sns.set_style("whitegrid")
palette = sns.color_palette("deep")

fig, axs = plt.subplots(1, 2, figsize=(16, 6))
for i, run_name in enumerate(history.history.keys()):
    df = history.get_epoch_df(run_name)
    axs[0].plot(df['epoch'], df['val_acc'], label=f"{run_name}", marker='o', linestyle='--', color=palette[i])
    axs[1].plot(df['epoch'], df['val_loss'], label=f"{run_name}", marker='o', linestyle='--', color=palette[i])

axs[0].set_title("Validation Accuracy vs. Epochs", fontsize=16)
axs[0].set_xlabel("Epoch"); axs[0].set_ylabel("Accuracy (%)"); axs[0].legend(); axs[0].grid(True)
axs[1].set_title("Validation Loss vs. Epochs", fontsize=16)
axs[1].set_xlabel("Epoch"); axs[1].set_ylabel("Loss"); axs[1].legend(); axs[1].grid(True)
plt.tight_layout(); plt.savefig('plots/accuracy_loss_curves_v3.png', dpi=300); plt.show()

slaw_run_name = next((name for name in history.history.keys() if "SLAW" in name), None)
if slaw_run_name:
    slaw_step_df = history.get_step_df(slaw_run_name)
    if not slaw_step_df.empty:
        slaw_step_df_smooth = slaw_step_df.rolling(window=100, min_periods=1).mean()
        fig, axs = plt.subplots(1, 2, figsize=(16, 6))
        axs[0].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['s_batch'], label='Batch Grad Norm (Smoothed)', alpha=0.8)
        axs[0].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['sharp_ema'], label='EMA of Grad Norm', linestyle='--', color='red')
        axs[0].set_title("SLAW: Batch Sharpness Proxy", fontsize=16)
        axs[0].set_xlabel("Training Step"); axs[0].set_ylabel("L2 Norm of Gradient"); axs[0].legend(); axs[0].grid(True); axs[0].set_yscale('log')
        ax2 = axs[1].twinx()
        p1, = axs[1].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['eps_mean'], label='Avg. $\\epsilon_i$', color=palette[0])
        p2, = ax2.plot(slaw_step_df_smooth.index, slaw_step_df_smooth['weight_mean'], label='Avg. $w_i$', color=palette[1])
        axs[1].set_title("SLAW: Adaptive Parameters", fontsize=16); axs[1].set_xlabel("Training Step")
        axs[1].set_ylabel("Avg. Epsilon", color=palette[0]); ax2.set_ylabel("Avg. Weight", color=palette[1])
        axs[1].tick_params(axis='y', labelcolor=palette[0]); ax2.tick_params(axis='y', labelcolor=palette[1])
        fig.legend(handles=[p1, p2], loc='upper right', bbox_to_anchor=(0.9, 0.9))
        plt.tight_layout(); plt.savefig('plots/slaw_dynamics_v3.png', dpi=300); plt.show()

print("Analysis complete.")

# all the above code i used was in one cell now for clariy and easy understanding for readeers i organize them in different cells but for
# understanding and running i would recommend to clone the repo and use that code.
# its my expirement lab so may be you guyz dont get completely thanks for your understanding...

# folloing is the results of the the above expirement.. i have included the figure in the paper ...









"""# custom datset class for expirement 2 and 3"""

import numpy as np
from torch.utils.data import Dataset

class NoisyCIFAR10(Dataset):
    """
    A wrapper for CIFAR-10 that introduces symmetric label noise.
    """
    def __init__(self, cifar_dataset, noise_rate=0.2, random_state=42):
        self.dataset = cifar_dataset
        self.num_classes = len(cifar_dataset.classes)
        self.noise_rate = noise_rate
        self.original_targets = np.array(cifar_dataset.targets)
        self.noisy_targets = self._create_noisy_labels(random_state)

        # replace the dataset's targets with our noisy ones
        self.dataset.targets = self.noisy_targets

        print(f"Created a NoisyCIFAR10 dataset with {noise_rate*100}% symmetric noise.")
        # verify a few samples
        correct_count = np.sum(self.original_targets == self.noisy_targets)
        print(f"Actual agreement with original labels: {correct_count / len(self.original_targets):.2%}")

    def _create_noisy_labels(self, random_state):
        rng = np.random.RandomState(random_state)
        noisy_targets = self.original_targets.copy()

        # determine which indices to corrupt
        num_samples = len(self.original_targets)
        num_to_corrupt = int(self.noise_rate * num_samples)
        indices_to_corrupt = rng.choice(num_samples, num_to_corrupt, replace=False)

        for idx in indices_to_corrupt:
            original_label = noisy_targets[idx]
            # choose a new label from any of the *other* classes
            potential_new_labels = [l for l in range(self.num_classes) if l != original_label]
            new_label = rng.choice(potential_new_labels)
            noisy_targets[idx] = new_label

        return list(noisy_targets)

    def __getitem__(self, index):
        # The __getitem__ from the original dataset will now return the noisy label
        return self.dataset[index]

    def __len__(self):
        return len(self.dataset)



"""# **Expirement-2 using noisy cifar 10 dataset**

## setup and imports
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
import pandas as pd
import pickle
import os

# for reproducibility
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# check for the presence of gpu for speed up trianing
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# create directories for saving results
os.makedirs('results', exist_ok=True)
os.makedirs('plots', exist_ok=True)

"""## The SLAW"""

class SLAW:
    """ SLAW (Version 3.2) - Uses retain_graph=True for the correct autograd handling. """
    def __init__(self, model, num_classes,
                 alpha=0.2, eps_min=0.0, eps_max=0.2, sharp_ema_decay=0.99,
                 tau=1.0, beta=1.0, gamma=0.7,
                 sharpness_scope='last_layer'):

        self.m = model
        self.K = num_classes
        self.alpha, self.eps_min, self.eps_max = alpha, eps_min, eps_max
        self.decay = sharp_ema_decay
        self.sharp_ema = 1.0
        self.tau, self.beta, self.gamma = tau, beta, gamma
        self.device = next(model.parameters()).device
        self.step_idx = 0

        self.sharpness_scope = sharpness_scope
        self._grad_params = self._get_params_for_sharpness()
        if not self._grad_params:
            print("Warning: SLAW could not find parameters. Defaulting to full model.")
            self.sharpness_scope = 'full'
            self._grad_params = [p for p in self.m.parameters() if p.requires_grad]

    def _get_params_for_sharpness(self):
        if self.sharpness_scope == 'last_layer':
            last_layer = None
            for module in reversed(list(self.m.modules())):
                if isinstance(module, (nn.Linear, nn.Conv2d)) and hasattr(module, 'weight') and module.weight.requires_grad:
                    last_layer = module
                    break
            if last_layer:
                print(f"SLAW: Using last layer ({type(last_layer).__name__}) for sharpness proxy.")
                return list(last_layer.parameters())
            else: return []
        else:
            print("SLAW: Using full model for sharpness proxy.")
            return [p for p in self.m.parameters() if p.requires_grad]

    @torch.no_grad()
    def _update_sharp_ema(self, s_batch_float):
        self.sharp_ema = self.decay * self.sharp_ema + (1 - self.decay) * s_batch_float

    @torch.no_grad()
    def _get_sals_targets(self, probs, y, s_batch_tensor):
        conf = probs.max(dim=1).values
        sharpness_scale = (s_batch_tensor / (self.sharp_ema + 1e-12)).clamp(min=0.1, max=10.0)
        eps_i = (self.alpha * sharpness_scale * (1.0 - conf)).clamp(self.eps_min, self.eps_max)

        B = y.size(0)
        off_target_fill = eps_i.unsqueeze(1) / (self.K - 1 + 1e-12)
        t = off_target_fill.expand(-1, self.K).clone()
        t.scatter_(1, y.unsqueeze(1), 1.0 - eps_i.unsqueeze(1))
        return t, eps_i

    def _get_sharpness_proxy(self, logits, y):
        with torch.enable_grad():
            ce_loss_for_grad = F.cross_entropy(logits, y, reduction='mean')
            grads = torch.autograd.grad(ce_loss_for_grad, self._grad_params, create_graph=False, retain_graph=True)
        s_batch = torch.sqrt(sum((g.detach()**2).sum() for g in grads) + 1e-12)
        return s_batch

    def __call__(self, logits, y):
        self.step_idx += 1

        s_batch_tensor = self._get_sharpness_proxy(logits, y)

        self._update_sharp_ema(s_batch_tensor.item())
        sals_targets, eps_i_stats = self._get_sals_targets(logits.softmax(dim=1).detach(), y, s_batch_tensor)

        log_probs = F.log_softmax(logits, dim=1)
        sals_per_sample = -(sals_targets * log_probs).sum(dim=1)

        with torch.no_grad():
            loss_vals = sals_per_sample.detach()
            mu, std = loss_vals.mean(), loss_vals.std() + 1e-8
            standardized_loss = (loss_vals - mu) / std
            weights = (torch.sigmoid(standardized_loss / self.tau).pow(self.beta) * self.gamma) + (1 - self.gamma)

        slaw_loss = (weights * sals_per_sample).mean()
        metrics = {'s_batch': s_batch_tensor.item(), 'sharp_ema': self.sharp_ema, 'eps_mean': eps_i_stats.mean().item(), 'weight_mean': weights.mean().item()}
        return slaw_loss, metrics

"""## Data loader and model definition."""

print("Preparing CIFAR-10 data...")
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])


# original trainset
trainset_clean = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)

# create the noisy version for the experiment
NOISE_LEVEL = 0.4  # Start with 20% then use 40%
trainset_noisy = NoisyCIFAR10(trainset_clean, noise_rate=NOISE_LEVEL)

# update  trainloader to use the noisy dataset
trainloader = torch.utils.data.DataLoader(trainset_noisy, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)

def get_model():
    model = torchvision.models.resnet18(weights='IMAGENET1K_V1')
    model.fc = nn.Linear(model.fc.in_features, 10)
    return model.to(device)

"""## Training and Evaluation Utilities"""

class History:
    def __init__(self): self.history = {}
    def new_run(self, name): self.history[name] = {'epochs': [], 'steps': []}
    def add_epoch_log(self, name, log): self.history[name]['epochs'].append(log)
    def add_step_log(self, name, log): self.history[name]['steps'].append(log)
    def get_epoch_df(self, name): return pd.DataFrame(self.history[name]['epochs'])
    def get_step_df(self, name): return pd.DataFrame(self.history[name]['steps'])
    def save(self, fp):
        with open(fp, 'wb') as f: pickle.dump(self.history, f)
    def load(self, fp):
        with open(fp, 'rb') as f: self.history = pickle.load(f)

def train_one_epoch(model, dataloader, criterion, optimizer, run_name, history_tracker):
    model.train()
    total_loss, total_correct, total_samples = 0, 0, 0
    progress_bar = tqdm(dataloader, desc="Training", leave=False)
    for inputs, targets in progress_bar:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        slaw_metrics = {}
        if isinstance(criterion, SLAW):
            loss, slaw_metrics = criterion(outputs, targets)
        else:
            loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * inputs.size(0)
        _, predicted = outputs.max(1)
        total_correct += predicted.eq(targets).sum().item()
        total_samples += inputs.size(0)
        if slaw_metrics: history_tracker.add_step_log(run_name, slaw_metrics)
        progress_bar.set_postfix(loss=total_loss/total_samples, acc=100.*total_correct/total_samples)
    return total_loss / total_samples, 100. * total_correct / total_samples

def evaluate(model, dataloader):
    model.eval()
    total_loss, total_correct, total_samples = 0, 0, 0
    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = F.cross_entropy(outputs, targets)
            total_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            total_correct += predicted.eq(targets).sum().item()
            total_samples += inputs.size(0)
    return total_loss / total_samples, 100. * total_correct / total_samples

"""## Main Script"""

N_EPOCHS = 50
LEARNING_RATE = 1e-3
WEIGHT_DECAY = 5e-4

HISTORY_FILE = f'results/cifar10_noise_{int(NOISE_LEVEL*100)}_history.pkl'



experiment_configs = {
    f"Baseline (CE) on {int(NOISE_LEVEL*100)}% Noise": {},

    f"SLAW (last_layer) on {int(NOISE_LEVEL*100)}% Noise": {
        'gamma': 0.9,
        'alpha': 0.2, 'eps_max': 0.2, 'tau': 1.0, 'beta': 1.0,
        'sharpness_scope': 'last_layer'
    },

}

try:
    history = History()
    history.load(HISTORY_FILE)
    print(f"Loaded existing history from {HISTORY_FILE}")
except FileNotFoundError:
    history = History()
    print("No existing history found. Starting a new one.")

for run_name, config in experiment_configs.items():
    if run_name in history.history and history.get_epoch_df(run_name).shape[0] >= N_EPOCHS:
        print(f"--> Skipping '{run_name}' as it's already completed in the history file.")
        continue
    # ... (Rest of the loop is identical and will work correctly)
    print(f"\n{'='*20} Starting Run: {run_name} {'='*20}")
    set_seed(42)
    model = get_model()
    history.new_run(run_name)

    criterion = SLAW(model, 10, **config) if "SLAW" in run_name else nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)

    best_val_acc = 0.0
    for epoch in range(N_EPOCHS):
        train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer, run_name, history)
        val_loss, val_acc = evaluate(model, testloader)
        scheduler.step()

        print(f"Epoch {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        history.add_epoch_log(run_name, {'epoch': epoch, 'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc})

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            model_path = f"results/{run_name}_best_model.pth"
            torch.save(model.state_dict(), model_path)
            print(f"  -> New best model saved to {model_path} (Acc: {best_val_acc:.2f}%)")

    print(f"Finished run {run_name}. Best Validation Accuracy: {best_val_acc:.2f}%")

    history.save(HISTORY_FILE)
    print(f"History updated and saved to '{HISTORY_FILE}'")

print("\nAll experiments complete.")

"""## PLOTTING AND ANALYSIS"""

print("\nGenerating plots from final history...")
sns.set_style("whitegrid")
palette = sns.color_palette("deep")

fig, axs = plt.subplots(1, 2, figsize=(16, 6))
for i, run_name in enumerate(history.history.keys()):
    df = history.get_epoch_df(run_name)
    axs[0].plot(df['epoch'], df['val_acc'], label=f"{run_name}", marker='o', linestyle='--', color=palette[i])
    axs[1].plot(df['epoch'], df['val_loss'], label=f"{run_name}", marker='o', linestyle='--', color=palette[i])

axs[0].set_title("Validation Accuracy vs. Epochs", fontsize=16)
axs[0].set_xlabel("Epoch"); axs[0].set_ylabel("Accuracy (%)"); axs[0].legend(); axs[0].grid(True)
axs[1].set_title("Validation Loss vs. Epochs", fontsize=16)
axs[1].set_xlabel("Epoch"); axs[1].set_ylabel("Loss"); axs[1].legend(); axs[1].grid(True)
plt.tight_layout(); plt.savefig('plots/accuracy_loss_curves_v3.png', dpi=300); plt.show()

slaw_run_name = next((name for name in history.history.keys() if "SLAW" in name), None)
if slaw_run_name:
    slaw_step_df = history.get_step_df(slaw_run_name)
    if not slaw_step_df.empty:
        slaw_step_df_smooth = slaw_step_df.rolling(window=100, min_periods=1).mean()
        fig, axs = plt.subplots(1, 2, figsize=(16, 6))
        axs[0].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['s_batch'], label='Batch Grad Norm (Smoothed)', alpha=0.8)
        axs[0].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['sharp_ema'], label='EMA of Grad Norm', linestyle='--', color='red')
        axs[0].set_title("SLAW: Batch Sharpness Proxy", fontsize=16)
        axs[0].set_xlabel("Training Step"); axs[0].set_ylabel("L2 Norm of Gradient"); axs[0].legend(); axs[0].grid(True); axs[0].set_yscale('log')
        ax2 = axs[1].twinx()
        p1, = axs[1].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['eps_mean'], label='Avg. $\\epsilon_i$', color=palette[0])
        p2, = ax2.plot(slaw_step_df_smooth.index, slaw_step_df_smooth['weight_mean'], label='Avg. $w_i$', color=palette[1])
        axs[1].set_title("SLAW: Adaptive Parameters", fontsize=16); axs[1].set_xlabel("Training Step")
        axs[1].set_ylabel("Avg. Epsilon", color=palette[0]); ax2.set_ylabel("Avg. Weight", color=palette[1])
        axs[1].tick_params(axis='y', labelcolor=palette[0]); ax2.tick_params(axis='y', labelcolor=palette[1])
        fig.legend(handles=[p1, p2], loc='upper right', bbox_to_anchor=(0.9, 0.9))
        plt.tight_layout(); plt.savefig('plots/slaw_dynamics_v3.png', dpi=300); plt.show()

print("Analysis complete.")

# same as above using the clone version is recomended for easy manupulation and reproducibility





"""## CALIBRATION ANALYSIS

the output of this cell is for 40% noise expirement. you can also use this cell for calculating the 20% noise model ece
"""

@torch.no_grad()
def calculate_ece(model, dataloader, n_bins=15, device='cuda'):
    """
    Calculates the Expected
    Calibration Error of a model.
    """
    model.eval()

    all_confidences = []
    all_correct = []

    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)
        logits = model(inputs)
        probs = F.softmax(logits, dim=1)

        confidences, predictions = torch.max(probs, dim=1)
        correct = predictions.eq(targets)

        all_confidences.append(confidences.cpu())
        all_correct.append(correct.cpu())

    all_confidences = torch.cat(all_confidences)
    all_correct = torch.cat(all_correct)

    # create bins of equal width
    bin_boundaries = torch.linspace(0, 1, n_bins + 1)
    bin_lowers = bin_boundaries[:-1]
    bin_uppers = bin_boundaries[1:]

    ece = 0.0
    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
        # find predictions within the confidence bin
        in_bin = (all_confidences > bin_lower) & (all_confidences <= bin_upper)
        prop_in_bin = in_bin.float().mean()

        if prop_in_bin > 0:
            accuracy_in_bin = all_correct[in_bin].float().mean()
            avg_confidence_in_bin = all_confidences[in_bin].mean()

            # add to ECE
            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin

    return ece.item()


print("\n" + "="*20 + " Final Model Evaluation " + "="*20)


try:
    history
except NameError:
    history = History()
    history.load(HISTORY_FILE)
    print(f"Loaded history from {HISTORY_FILE} for final analysis.")

for run_name in experiment_configs.keys():
    print(f"\nAnalyzing run: '{run_name}'")

    #load the best model
    model = get_model()
    model_path = f"results/{run_name}_best_model.pth"

    try:
        model.load_state_dict(torch.load(model_path, map_location=device))
    except FileNotFoundError:
        print(f"  -> Model file not found at {model_path}. Skipping.")
        continue


    df = history.get_epoch_df(run_name)
    best_acc = df['val_acc'].max()

    # calculate ece on test set
    ece_score = calculate_ece(model, testloader, device=device)

    print(f"  -> Best Validation Accuracy: {best_acc:.2f}%")
    print(f"  -> Expected Calibration Error (ECE): {ece_score:.4f}")

"""## RELIABILITY DIAGRAMS"""

@torch.no_grad()
def get_reliability_data(model, dataloader, n_bins=15, device='cuda'):
    """
    Gathers data required for a reliability diagram.
    """
    model.eval()
    all_confidences, all_correct = [], []

    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)
        logits = model(inputs)
        probs = F.softmax(logits, dim=1)
        confidences, predictions = torch.max(probs, dim=1)
        correct = predictions.eq(targets)
        all_confidences.append(confidences.cpu())
        all_correct.append(correct.cpu())

    all_confidences = torch.cat(all_confidences)
    all_correct = torch.cat(all_correct)

    bin_boundaries = torch.linspace(0, 1, n_bins + 1)
    bin_lowers, bin_uppers = bin_boundaries[:-1], bin_boundaries[1:]

    bin_accuracies, bin_confidences, bin_proportions = [], [], []

    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
        in_bin = (all_confidences > bin_lower) & (all_confidences <= bin_upper)
        prop_in_bin = in_bin.float().mean()
        bin_proportions.append(prop_in_bin.item())

        if prop_in_bin > 0:
            accuracy_in_bin = all_correct[in_bin].float().mean()
            avg_confidence_in_bin = all_confidences[in_bin].mean()
            bin_accuracies.append(accuracy_in_bin.item())
            bin_confidences.append(avg_confidence_in_bin.item())
        else:
            bin_accuracies.append(0)
            bin_confidences.append(0)

    return bin_accuracies, bin_confidences, bin_proportions


def plot_reliability_diagram(ax, bin_accuracies, bin_confidences, bin_proportions, title):
    """
    Plots a reliability diagram on a given matplotlib axis.
    """
    n_bins = len(bin_accuracies)
    bin_width = 1.0 / n_bins

    positions = np.linspace(0.0 + bin_width / 2, 1.0 - bin_width / 2, n_bins)

    bar_plot = ax.bar(positions, bin_accuracies, width=bin_width * 0.9, edgecolor="black", alpha=0.7)

    for i, (conf, acc, prop) in enumerate(zip(bin_confidences, bin_accuracies, bin_proportions)):
        if prop > 0:
            if acc < conf: # Over-confident
                ax.bar(positions[i], conf - acc, bottom=acc, width=bin_width * 0.9, color='red', alpha=0.5, edgecolor="black", hatch='//')
            else: # Under-confident
                # Blue bar for the gap
                ax.bar(positions[i], acc - conf, bottom=conf, width=bin_width * 0.9, color='blue', alpha=0.5, edgecolor="black", hatch='\\')


    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_xlabel("Confidence", fontsize=14)
    ax.set_ylabel("Accuracy", fontsize=14)
    ax.set_title(title, fontsize=16)
    ax.grid(True, linestyle='-', alpha=0.5)
    ax.legend()


# --- Main Analysis Loop for 40% Noise Experiment ---
print("\n" + "="*20 + " Reliability Diagram Analysis (40% Noise) " + "="*20)

NOISE_LEVEL = 0.4
HISTORY_FILE = f'results/cifar10_noise_{int(NOISE_LEVEL*100)}_history.pkl'

experiment_configs = {
    f"Baseline (CE) on {int(NOISE_LEVEL*100)}% Noise": {},
    f"SLAW (last_layer) on {int(NOISE_LEVEL*100)}% Noise": {}
}

fig, axs = plt.subplots(1, 2, figsize=(18, 8))

for i, run_name in enumerate(experiment_configs.keys()):
    print(f"\nGenerating diagram for: '{run_name}'")

    model = get_model()
    model_path = f"results/{run_name}_best_model.pth"

    try:
        model.load_state_dict(torch.load(model_path, map_location=device))
    except FileNotFoundError:
        print(f"  -> Model file not found at {model_path}. Skipping.")
        continue

    bin_accs, bin_confs, bin_props = get_reliability_data(model, testloader, device=device)

    plot_reliability_diagram(axs[i], bin_accs, bin_confs, bin_props, title=run_name)

plt.tight_layout()
plt.savefig(f'plots/reliability_diagram_noise_{int(NOISE_LEVEL*100)}.png', dpi=300)
plt.show()

"""# Ablation study Expirement

setup and imports
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
import pandas as pd
import pickle
import os


def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


os.makedirs('results', exist_ok=True)
os.makedirs('plots', exist_ok=True)

"""## The SLAW"""

class SLAW:
    """ SLAW (Version 4 - Ablation Ready) """
    def __init__(self, model, num_classes,
                 alpha=0.2, eps_min=0.0, eps_max=0.2, sharp_ema_decay=0.99,
                 tau=1.0, beta=1.0, gamma=0.7,
                 sharpness_scope='last_layer',

                 use_sals=True, use_law=True):

        self.m = model
        self.K = num_classes
        self.alpha, self.eps_min, self.eps_max = alpha, eps_min, eps_max
        self.decay = sharp_ema_decay
        self.sharp_ema = 1.0
        self.tau, self.beta, self.gamma = tau, beta, gamma
        self.device = next(model.parameters()).device
        self.step_idx = 0

        self.sharpness_scope = sharpness_scope
        self._grad_params = self._get_params_for_sharpness()


        self.use_sals = use_sals
        self.use_law = use_law

        if self.use_sals and not self._grad_params:
             print("Warning: SLAW could not find params for SALS. Disabling.")
             self.use_sals = False

    def _get_params_for_sharpness(self):
        if self.sharpness_scope == 'last_layer':
            last_layer = None
            for module in reversed(list(self.m.modules())):
                if isinstance(module, (nn.Linear, nn.Conv2d)) and hasattr(module, 'weight') and module.weight.requires_grad:
                    last_layer = module
                    break
            if last_layer:
                print(f"SLAW: Using last layer ({type(last_layer).__name__}) for sharpness proxy.")
                return list(last_layer.parameters())
            else: return []
        else:
            print("SLAW: Using full model for sharpness proxy.")
            return [p for p in self.m.parameters() if p.requires_grad]

    @torch.no_grad()
    def _update_sharp_ema(self, s_batch_float):
      self.sharp_ema = self.decay * self.sharp_ema + (1 - self.decay) * s_batch_float

    @torch.no_grad()
    def _get_sals_targets(self, probs, y, s_batch_tensor):
        conf = probs.max(dim=1).values
        sharpness_scale = (s_batch_tensor / (self.sharp_ema + 1e-12)).clamp(min=0.1, max=10.0)
        eps_i = (self.alpha * sharpness_scale * (1.0 - conf)).clamp(self.eps_min, self.eps_max)
        B = y.size(0)
        off_target_fill = eps_i.unsqueeze(1) / (self.K - 1 + 1e-12)
        t = off_target_fill.expand(-1, self.K).clone()
        t.scatter_(1, y.unsqueeze(1), 1.0 - eps_i.unsqueeze(1))
        return t, eps_i

    def _get_sharpness_proxy(self, logits, y):
        with torch.enable_grad():
            ce_loss_for_grad = F.cross_entropy(logits, y, reduction='mean')
            grads = torch.autograd.grad(ce_loss_for_grad, self._grad_params, create_graph=False, retain_graph=True)
        s_batch = torch.sqrt(sum((g.detach()**2).sum() for g in grads) + 1e-12)
        return s_batch


    def __call__(self, logits, y):
        self.step_idx += 1
        metrics = {}



        # calculate the base per-sample loss
        if self.use_sals:
            s_batch_tensor = self._get_sharpness_proxy(logits, y)
            self._update_sharp_ema(s_batch_tensor.item())
            sals_targets, eps_i_stats = self._get_sals_targets(logits.softmax(dim=1).detach(), y, s_batch_tensor)
            log_probs = F.log_softmax(logits, dim=1)
            per_sample_loss = -(sals_targets * log_probs).sum(dim=1)
            metrics.update({'s_batch': s_batch_tensor.item(), 'sharp_ema': self.sharp_ema, 'eps_mean': eps_i_stats.mean().item()})
        else:
            # for LAW-only or CE, the base loss is standard Cross-Entropy
            per_sample_loss = F.cross_entropy(logits, y, reduction='none')

        #  calculate the final batch loss
        if self.use_law:
            with torch.no_grad():
                loss_vals = per_sample_loss.detach()
                mu, std = loss_vals.mean(), loss_vals.std() + 1e-8
                standardized_loss = (loss_vals - mu) / std
                weights = (torch.sigmoid(standardized_loss / self.tau).pow(self.beta) * self.gamma) + (1 - self.gamma)

            final_loss = (weights * per_sample_loss).mean()
            metrics.update({'weight_mean': weights.mean().item()})
        else:
            # for SALS-only or CE, the final loss is a simple mean
            final_loss = per_sample_loss.mean()

        return final_loss, metrics

"""## data loading and model defintion"""

print("Preparing CIFAR-10 data...")
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])


# original trainset
trainset_clean = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)

# create the noisy version for the experiment
NOISE_LEVEL = 0.2  # Start with 20% then use 40%
trainset_noisy = NoisyCIFAR10(trainset_clean, noise_rate=NOISE_LEVEL)

# update  trainloader to use the noisy dataset
trainloader = torch.utils.data.DataLoader(trainset_noisy, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)

def get_model():
    model = torchvision.models.resnet18(weights='IMAGENET1K_V1')
    model.fc = nn.Linear(model.fc.in_features, 10)
    return model.to(device)

"""## Training And evaluation MAtrixes"""

class History:
    def __init__(self): self.history = {}
    def new_run(self, name): self.history[name] = {'epochs': [], 'steps': []}
    def add_epoch_log(self, name, log): self.history[name]['epochs'].append(log)
    def add_step_log(self, name, log): self.history[name]['steps'].append(log)
    def get_epoch_df(self, name): return pd.DataFrame(self.history[name]['epochs'])
    def get_step_df(self, name): return pd.DataFrame(self.history[name]['steps'])
    def save(self, fp):
        with open(fp, 'wb') as f: pickle.dump(self.history, f)
    def load(self, fp):
        with open(fp, 'rb') as f: self.history = pickle.load(f)

def train_one_epoch(model, dataloader, criterion, optimizer, run_name, history_tracker):
    model.train()
    total_loss, total_correct, total_samples = 0, 0, 0
    progress_bar = tqdm(dataloader, desc="Training", leave=False)
    for inputs, targets in progress_bar:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        slaw_metrics = {}
        if isinstance(criterion, SLAW):
            loss, slaw_metrics = criterion(outputs, targets)
        else:
            loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * inputs.size(0)
        _, predicted = outputs.max(1)
        total_correct += predicted.eq(targets).sum().item()
        total_samples += inputs.size(0)
        if slaw_metrics: history_tracker.add_step_log(run_name, slaw_metrics)
        progress_bar.set_postfix(loss=total_loss/total_samples, acc=100.*total_correct/total_samples)
    return total_loss / total_samples, 100. * total_correct / total_samples

def evaluate(model, dataloader):
    model.eval()
    total_loss, total_correct, total_samples = 0, 0, 0
    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = F.cross_entropy(outputs, targets)
            total_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            total_correct += predicted.eq(targets).sum().item()
            total_samples += inputs.size(0)
    return total_loss / total_samples, 100. * total_correct / total_samples

"""## main script"""

N_EPOCHS = 50
LEARNING_RATE = 1e-3
WEIGHT_DECAY = 5e-4

HISTORY_FILE = f'results/cifar10_noise_{int(NOISE_LEVEL*100)}_history.pkl'



# this dictionary now defines our entire ablation study
experiment_configs = {
    # you can comment out runs you've already completed if their history is saved
    f"Baseline (CE) on {int(NOISE_LEVEL*100)}% Noise": {
        'use_sals': False, 'use_law': False
    },
    f"SALS-only on {int(NOISE_LEVEL*100)}% Noise": {
        'use_sals': True, 'use_law': False, 'gamma': 0.9 # Pass gamma just in case, won't be used
    },
    f"LAW-only on {int(NOISE_LEVEL*100)}% Noise": {
        'use_sals': False, 'use_law': True, 'gamma': 0.9
    },
    f"SLAW (Full) on {int(NOISE_LEVEL*100)}% Noise": {
        'use_sals': True, 'use_law': True, 'gamma': 0.9
    }
}

try:
    history = History()
    history.load(HISTORY_FILE)
    print(f"Loaded existing history from {HISTORY_FILE}")
except FileNotFoundError:
    history = History()
    print("No existing history found. Starting a new one.")

for run_name, config in experiment_configs.items():
    if run_name in history.history and history.get_epoch_df(run_name).shape[0] >= N_EPOCHS:
        print(f"--> Skipping '{run_name}' as it's already completed in the history file.")
        continue
    print(f"\n{'='*20} Starting Run: {run_name} {'='*20}")
    set_seed(42)
    model = get_model()
    history.new_run(run_name)


    print(f"  -> Config: use_sals={config.get('use_sals', True)}, use_law={config.get('use_law', True)}")
    if "Baseline (CE)" in run_name:
        criterion = nn.CrossEntropyLoss()
    else:
        criterion = SLAW(model, 10, **config)

    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)

    best_val_acc = 0.0
    for epoch in range(N_EPOCHS):
        train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer, run_name, history)
        val_loss, val_acc = evaluate(model, testloader)
        scheduler.step()

        print(f"Epoch {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        history.add_epoch_log(run_name, {'epoch': epoch, 'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc})

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            model_path = f"results/{run_name}_best_model.pth"
            torch.save(model.state_dict(), model_path)
            print(f"  -> New best model saved to {model_path} (Acc: {best_val_acc:.2f}%)")

    print(f"Finished run {run_name}. Best Validation Accuracy: {best_val_acc:.2f}%")

    history.save(HISTORY_FILE)
    print(f"History updated and saved to '{HISTORY_FILE}'")

print("\nAll experiments complete.")

"""## plotting and analysis"""

print("\nGenerating plots from final history...")
sns.set_style("whitegrid")
palette = sns.color_palette("deep")

fig, axs = plt.subplots(1, 2, figsize=(16, 6))
for i, run_name in enumerate(history.history.keys()):
    df = history.get_epoch_df(run_name)
    axs[0].plot(df['epoch'], df['val_acc'], label=f"{run_name}", marker='o', linestyle='--', color=palette[i])
    axs[1].plot(df['epoch'], df['val_loss'], label=f"{run_name}", marker='o', linestyle='--', color=palette[i])

axs[0].set_title("Validation Accuracy vs. Epochs", fontsize=16)
axs[0].set_xlabel("Epoch"); axs[0].set_ylabel("Accuracy (%)"); axs[0].legend(); axs[0].grid(True)
axs[1].set_title("Validation Loss vs. Epochs", fontsize=16)
axs[1].set_xlabel("Epoch"); axs[1].set_ylabel("Loss"); axs[1].legend(); axs[1].grid(True)
plt.tight_layout(); plt.savefig('plots/accuracy_loss_curves_v3.png', dpi=300); plt.show()

slaw_run_name = next((name for name in history.history.keys() if "SLAW" in name), None)
if slaw_run_name:
    slaw_step_df = history.get_step_df(slaw_run_name)
    if not slaw_step_df.empty:
        slaw_step_df_smooth = slaw_step_df.rolling(window=100, min_periods=1).mean()
        fig, axs = plt.subplots(1, 2, figsize=(16, 6))
        axs[0].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['s_batch'], label='Batch Grad Norm (Smoothed)', alpha=0.8)
        axs[0].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['sharp_ema'], label='EMA of Grad Norm', linestyle='--', color='red')
        axs[0].set_title("SLAW: Batch Sharpness Proxy", fontsize=16)
        axs[0].set_xlabel("Training Step"); axs[0].set_ylabel("L2 Norm of Gradient"); axs[0].legend(); axs[0].grid(True); axs[0].set_yscale('log')
        ax2 = axs[1].twinx()
        p1, = axs[1].plot(slaw_step_df_smooth.index, slaw_step_df_smooth['eps_mean'], label='Avg. $\\epsilon_i$', color=palette[0])
        p2, = ax2.plot(slaw_step_df_smooth.index, slaw_step_df_smooth['weight_mean'], label='Avg. $w_i$', color=palette[1])
        axs[1].set_title("SLAW: Adaptive Parameters", fontsize=16); axs[1].set_xlabel("Training Step")
        axs[1].set_ylabel("Avg. Epsilon", color=palette[0]); ax2.set_ylabel("Avg. Weight", color=palette[1])
        axs[1].tick_params(axis='y', labelcolor=palette[0]); ax2.tick_params(axis='y', labelcolor=palette[1])
        fig.legend(handles=[p1, p2], loc='upper right', bbox_to_anchor=(0.9, 0.9))
        plt.tight_layout(); plt.savefig('plots/slaw_dynamics_v3.png', dpi=300); plt.show()

print("Analysis complete.")

# same like above expirement ... using the cloned version is recommended